{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa32afe",
   "metadata": {},
   "source": [
    "# Notebook Jupyter para uso de YOLOv11 (Proj. Metis)\n",
    "\n",
    "En este notebook, se presenta una guía paso a paso para utilizar el modelo YOLOv11 para detección de objetos. Este proyecto es parte del Proyecto Metis y está diseñado para facilitar la implementación y uso de YOLOv11 en diversas aplicaciones, asi mismo tener esa guia para su utilizacion futura con Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d960202",
   "metadata": {},
   "source": [
    "## Prueba rápida para confirmar que estás usando el entorno correcto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4329b3",
   "metadata": {},
   "source": [
    "Se importan las librerías necesarias y se imprime la versión de Torch, la disponibilidad del dispositivo (CPU o GPU) y la versión de Ultralytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8178a04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.8.0+cpu\n",
      "Device available: CPU\n",
      "Ultralytics version: 8.3.213\n",
      "c:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import torch, ultralytics, cv2, matplotlib, numpy, pandas, sys\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Device available:\", \"CUDA\" if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"Ultralytics version:\", ultralytics.__version__)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d999a",
   "metadata": {},
   "source": [
    "Se instala roboflow y se configura la API key para acceder a los datasets alojados en Roboflow. \n",
    "La API key se obtiene desde la cuenta de Roboflow una vez se copia la lista de comandos desde roboflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c058b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (1.2.11)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (2025.10.5)\n",
      "Requirement already satisfied: idna==3.7 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (1.4.9)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (3.10.7)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (2.2.6)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (11.3.0)\n",
      "Requirement already satisfied: pi-heif<2 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: pillow-avif-plugin<2 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (2.32.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (6.0.3)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from matplotlib->roboflow) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from matplotlib->roboflow) (4.60.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from matplotlib->roboflow) (3.2.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\metisyolov11\\lib\\site-packages (from requests->roboflow) (3.4.3)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "ename": "RoboflowError",
     "evalue": "{\n    \"error\": {\n        \"message\": \"Unsupported request. `GET /metis-bwgip/clasification-7s2nv-wntxf` does not exist or cannot be loaded due to missing permissions.\",\n        \"type\": \"GraphMethodException\",\n        \"hint\": \"You can see your active workspace by issuing a GET request to `/` with your `api_key`.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRoboflowError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mroboflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Roboflow\n\u001b[32m      4\u001b[39m rf = Roboflow(api_key=\u001b[33m\"\u001b[39m\u001b[33miSUpQqSxeaupKuugZKmc\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m project = \u001b[43mrf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mworkspace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetis-bwgip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclasification-7s2nv-wntxf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m version = project.version(\u001b[32m1\u001b[39m)\n\u001b[32m      7\u001b[39m dataset = version.download(\u001b[33m\"\u001b[39m\u001b[33myolov11\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\roboflow\\core\\workspace.py:94\u001b[39m, in \u001b[36mWorkspace.project\u001b[39m\u001b[34m(self, project_id)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m project_id:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m project is not available in this (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) workspace\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m dataset_info = \u001b[43mrfapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_project\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__api_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m dataset_info = dataset_info[\u001b[33m\"\u001b[39m\u001b[33mproject\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Project(\u001b[38;5;28mself\u001b[39m.__api_key, dataset_info, \u001b[38;5;28mself\u001b[39m.model_format)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\roboflow\\adapters\\rfapi.py:47\u001b[39m, in \u001b[36mget_project\u001b[39m\u001b[34m(api_key, workspace_url, project_url)\u001b[39m\n\u001b[32m     45\u001b[39m response = requests.get(url)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RoboflowError(response.text)\n\u001b[32m     48\u001b[39m result = response.json()\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mRoboflowError\u001b[39m: {\n    \"error\": {\n        \"message\": \"Unsupported request. `GET /metis-bwgip/clasification-7s2nv-wntxf` does not exist or cannot be loaded due to missing permissions.\",\n        \"type\": \"GraphMethodException\",\n        \"hint\": \"You can see your active workspace by issuing a GET request to `/` with your `api_key`.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"iSUpQqSxeaupKuugZKmc\")\n",
    "project = rf.workspace(\"metis-bwgip\").project(\"clasification-7s2nv-wntxf\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov11\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06ea35",
   "metadata": {},
   "source": [
    "Mostrar las caracteristicas de Ultralytics y Torch para confirmar que el entorno está correctamente configurado para usar YOLOv11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcb9462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ultralytics\n",
      "Version: 8.3.213\n",
      "Summary: Ultralytics YOLO 🚀 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\n",
      "Home-page: https://ultralytics.com\n",
      "Author: \n",
      "Author-email: Glenn Jocher <glenn.jocher@ultralytics.com>, Jing Qiu <jing.qiu@ultralytics.com>\n",
      "License: AGPL-3.0\n",
      "Location: c:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\n",
      "Requires: matplotlib, numpy, opencv-python, pillow, polars, psutil, pyyaml, requests, scipy, torch, torchvision, ultralytics-thop\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip show ultralytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbaea7",
   "metadata": {},
   "source": [
    "Establecer el modelo que se va a ejecutar de YOLO y tambien el dataset con el que se va a entrenar ese modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf01d9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.217 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.213  Python-3.11.13 torch-2.8.0+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Clasification-1/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\stw01\\Desktop\\Kyma\\Metis\\runs\\detect\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.50.2 ms, read: 14.29.8 MB/s, size: 25.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Clasification-1\\train\\labels.cache... 257 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 257/257 70.2Kit/s 0.0s\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 3, len(boxes) = 257. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.60.2 ms, read: 17.49.3 MB/s, size: 27.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Clasification-1\\valid\\labels.cache... 64 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 64/64  0.0s\n",
      "Plotting labels to C:\\Users\\stw01\\Desktop\\Kyma\\Metis\\runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\stw01\\Desktop\\Kyma\\Metis\\runs\\detect\\train2\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      2.054      6.412      2.148          0        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 4:234.9ss\n",
      "WARNING NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% ━━━━━━────── 1/2 0.0it/s 14.4s<47.9sWARNING NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 27.6s\n",
      "                   all         64         64      0.182     0.0902     0.0599     0.0203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.882      3.215      2.011          1        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 3:122.6ss\n",
      "WARNING NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% ━━━━━━────── 1/2 0.0it/s 11.8s<39.4sWARNING NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 23.1s\n",
      "                   all         64         64      0.209      0.228      0.115     0.0464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      2.025      2.701      2.132          1        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 3:032.8ss\n",
      "WARNING NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% ━━━━━━────── 1/2 0.0it/s 11.2s<37.2sWARNING NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 22.3s\n",
      "                   all         64         64     0.0809      0.084     0.0496     0.0183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G       2.04      2.365      2.124          3        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:592.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 17.9s8.2s\n",
      "                   all         64         64     0.0286     0.0982     0.0133     0.0031\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.923      2.387      2.046          0        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 3:002.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 15.3s5.2s\n",
      "                   all         64         64      0.514     0.0395    0.00258   0.000892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      2.058      2.269      2.169          3        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 3:013.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 16.4s8.1s\n",
      "                   all         64         64    0.00904      0.116    0.00251   0.000482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      2.031      2.321      2.129          3        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:542.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 15.1s5.2s\n",
      "                   all         64         64     0.0215     0.0962     0.0116    0.00281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G      2.073      2.224      2.134          3        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:582.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 16.3s7.0s\n",
      "                   all         64         64   0.000746      0.203   0.000504   0.000109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G      1.982      2.154      2.067          2        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:552.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 16.6s8.6s\n",
      "                   all         64         64     0.0336     0.0577     0.0152    0.00338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G      2.011      2.123      2.062          4        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:582.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 14.7s5.0s\n",
      "                   all         64         64     0.0277      0.241     0.0333    0.00749\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G      2.086      2.136      2.134          1        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:512.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 14.1s3.2s\n",
      "                   all         64         64     0.0905      0.291     0.0677     0.0178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G      2.029      2.032      2.054          1        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:532.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 14.5s4.6s\n",
      "                   all         64         64     0.0796      0.164     0.0757     0.0221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G       1.97      1.966      2.028          2        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:522.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 13.9s3.3s\n",
      "                   all         64         64      0.257      0.304      0.141     0.0434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G      1.978      1.969      2.028          1        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:572.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 15.4s7.2s\n",
      "                   all         64         64      0.188      0.453      0.194      0.052\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G      2.132      2.026      2.169          1        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 3:002.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 15.0s6.4s\n",
      "                   all         64         64      0.316      0.265      0.249     0.0736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G      1.948      2.042      2.003          1        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:512.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 14.1s3.3s\n",
      "                   all         64         64      0.308      0.472      0.328      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G      1.888      1.898      1.977          4        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:552.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 14.3s3.9s\n",
      "                   all         64         64       0.43      0.693      0.478       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G      1.741      1.895      1.793          0        640: 100% ━━━━━━━━━━━━ 17/17 0.1it/s 2:512.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.1it/s 13.4s2.4s\n",
      "                   all         64         64      0.357      0.278      0.251     0.0921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G      1.962      1.798      2.001         29        640: 29% ━━━╸──────── 5/17 0.2it/s 52.9s<1:03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[33m'\u001b[39m\u001b[33myolo11s.pt\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Modelo preentrenado pequeño\u001b[39;00m\n\u001b[32m      5\u001b[39m data_path=\u001b[33m\"\u001b[39m\u001b[33mClasification-1/data.yaml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\ultralytics\\engine\\model.py:800\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:236\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    233\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:420\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    418\u001b[39m     loss, \u001b[38;5;28mself\u001b[39m.loss_items = unwrap_model(\u001b[38;5;28mself\u001b[39m.model).loss(batch, preds)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     loss, \u001b[38;5;28mself\u001b[39m.loss_items = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28mself\u001b[39m.loss = loss.sum()\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK != -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:138\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[32m    126\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict(x, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:338\u001b[39m, in \u001b[36mBaseModel.loss\u001b[39m\u001b[34m(self, batch, preds)\u001b[39m\n\u001b[32m    335\u001b[39m     \u001b[38;5;28mself\u001b[39m.criterion = \u001b[38;5;28mself\u001b[39m.init_criterion()\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.criterion(preds, batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:139\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:157\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:180\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    181\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:81\u001b[39m, in \u001b[36mConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     72\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m    Apply convolution, batch normalization and activation to input tensor.\u001b[39;00m\n\u001b[32m     74\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \u001b[33;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28mself\u001b[39m.bn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\MetisYOLOv11\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = YOLO('yolo11s.pt')  # Modelo preentrenado pequeño\n",
    "    data_path=\"Clasification-1/data.yaml\"\n",
    "    model.train(data=data_path, epochs=50, imgsz=640, device='cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3c721",
   "metadata": {},
   "source": [
    "Establecer el modelo entrenado con el dataset anteriormente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82c21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "custome_model = YOLO(\"runs/detect/train/weights/best.pt\")  # Cargar el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b74b9f",
   "metadata": {},
   "source": [
    "Detección en imagenes que se encuentran en una carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d92376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\07259f195019fac7e4785094ba919229-783x450.jpg: 384x640 (no detections), 151.2ms\n",
      "image 2/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\20241224_162547-removebg-preview-400x533.png: 640x480 (no detections), 199.1ms\n",
      "image 3/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\226775985_tcimg_2535B68F.jpg: 640x480 (no detections), 132.3ms\n",
      "image 4/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\46129689.jpg: 480x640 (no detections), 201.2ms\n",
      "image 5/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\72-728095_agua-brisa-sin-gas-plastic-bottle-clipart.png: 640x288 (no detections), 155.2ms\n",
      "image 6/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\Diseno-sin-titulo-6-4.jpg: 640x640 2 sodas, 169.0ms\n",
      "image 7/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\Gaseosa-Postobon-3L-x-6-Sabores-Surtidos-piragua.jpg: 640x640 (no detections), 148.2ms\n",
      "image 8/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\Parque_Basura.jpeg: 640x640 (no detections), 159.0ms\n",
      "image 9/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\Postobon-Colombiana-las-2.png: 640x480 (no detections), 117.5ms\n",
      "image 10/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\Prueba4.jpg: 448x640 (no detections), 120.9ms\n",
      "image 11/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\agua-crital-x600ml-con-gas.jpg: 640x640 3 plasticos, 157.6ms\n",
      "image 12/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\beyondplastics.org-dentro.jpg: 448x640 (no detections), 110.5ms\n",
      "image 13/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\coca-cola-botellas.jpg: 384x640 1 plastico, 105.6ms\n",
      "image 14/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\cocacola-playa-unsplash.jpg: 448x640 (no detections), 118.7ms\n",
      "image 15/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\coke-bottle-1024x576.jpg: 384x640 (no detections), 102.8ms\n",
      "image 16/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\colombiana-2-litros-1.jpeg: 640x320 (no detections), 137.0ms\n",
      "image 17/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\front_de.3.full.jpg: 640x224 (no detections), 114.6ms\n",
      "image 18/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\front_en.3.full.jpg: 640x320 (no detections), 90.9ms\n",
      "image 19/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\front_pt.26.full.jpg: 640x192 (no detections), 106.0ms\n",
      "image 20/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\gaseosa-postobon-sin-azucar-botella-x-1-litro-manzana.jpg: 640x640 (no detections), 159.6ms\n",
      "image 21/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\images.jpg: 640x480 (no detections), 131.3ms\n",
      "image 22/22 c:\\Users\\stw01\\Desktop\\Kyma\\Metis\\Prueba\\stock-photo-empty-bottle-soft-drink-bottles-kids-love-soft-drinks-gombong-kebumen-regency-central-java-2204130333.jpg: 544x640 (no detections), 173.9ms\n",
      "Speed: 2.9ms preprocess, 139.2ms inference, 0.7ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    }
   ],
   "source": [
    "res=custome_model(\"Prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b52b9de",
   "metadata": {},
   "source": [
    "Mostrar una imagen en especifico de la prueba de detección que se realizo anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21a6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[5].show()  # Mostrar resultados con Matplotlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MetisYOLOv11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
